{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uTXF9oHWmB7"
      },
      "source": [
        "# Домашнее задание 10\n",
        "\n",
        "##### Автор: [Татьяна Гайнцева](https://www.linkedin.com/in/tgaintseva/), @atmyre\n",
        "\n",
        "В этом задании вам предстоит построить автоэнкодер, который будет сжимать и восстанавливать лица людей. Мы будем работать с тем же датасетом LFW, что был на занятии."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPRTwJWsI-tf"
      },
      "source": [
        "## Подготовка датасета"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRPeoLMQxk2A"
      },
      "source": [
        "Часть подготовки датасета полностью написана, изменять ее не нужно"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_5ZOBX01dVt"
      },
      "source": [
        "Импортируем нужные библиотеки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmRRgBlgK_ag"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brEQukCkAJy6"
      },
      "source": [
        "#### Скачивание и подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-CiehsK1fvt"
      },
      "source": [
        "Скачиваем данные. Мы будем обучать автоэнкодер на датасете лиц людей [Labeled faces in the Wild](http://vis-www.cs.umass.edu/lfw/) (LFW). Ячейка ниже скачивает и распаковывает датасет:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgAwi6LuJBE6"
      },
      "outputs": [],
      "source": [
        "! wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz -O tmp.tgz\n",
        "os.system(\"tar xvzf tmp.tgz && rm tmp.tgz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc9Zz1hl1vFI"
      },
      "source": [
        "Наши картинки скачались в папку lfw-deepfunneled. Давайте пройдемся по ней и соберем массив путей до картинок датасета:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm9JTUJnTYIz"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk('lfw-deepfunneled'):\n",
        "    for fname in filenames:\n",
        "        if fname.endswith(\".jpg\"):\n",
        "            fpath = os.path.join(dirpath,fname)\n",
        "            image = Image.open(fpath)\n",
        "            images.append(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SodcV_dDt14g"
      },
      "outputs": [],
      "source": [
        "len(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88zj8G6M14E8"
      },
      "source": [
        "Отрисуем несколько картинок, чтобы понять, с чем мы имеем дело:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyigQOWJKkU8"
      },
      "outputs": [],
      "source": [
        "def plot_gallery(images, n_row=3, n_col=6, from_torch=False):\n",
        "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
        "\n",
        "    # нужно поставить from_torch=True, если функция plot_gallery\n",
        "    # вызывается для images типа torch.Tensor\n",
        "    if from_torch:\n",
        "        images = [x.data.numpy().transpose(1, 2, 0) for x in images]\n",
        "\n",
        "    plt.figure(figsize=(1.5 * n_col, 1.7 * n_row))\n",
        "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
        "\n",
        "    for i in range(n_row * n_col):\n",
        "        plt.subplot(n_row, n_col, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "\n",
        "        # убираем отрисовку координат\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgDNEMypK6ID"
      },
      "outputs": [],
      "source": [
        "plot_gallery(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTm3f_YB2MqU"
      },
      "source": [
        "Посмотрим, какие размерности у наших картинок:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfGdSCB3UCpT"
      },
      "outputs": [],
      "source": [
        "np.array(images[0]).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBHVtsIE2QVt"
      },
      "source": [
        "Создадим датасет Faces для работы с нашими данными:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-ueN5CVLwLD"
      },
      "outputs": [],
      "source": [
        "class Faces(Dataset):\n",
        "    def __init__(self, faces):\n",
        "        self.data = faces\n",
        "        self.transform = transforms.Compose([\n",
        "                                    transforms.CenterCrop((90, 90)),\n",
        "                                    transforms.Resize((64, 64)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "                                    ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        x = self.data[index]\n",
        "        return self.transform(x).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k8l05gT3cZl"
      },
      "source": [
        "Создадим датасет и посмотрим на несколько картинок из него:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzAI9T8CUoMv"
      },
      "outputs": [],
      "source": [
        "dataset = Faces(images)\n",
        "\n",
        "# dataset[0] — это вызов метода __getitem__(0)\n",
        "img = dataset[0]\n",
        "\n",
        "print(img.shape)\n",
        "\n",
        "# отрисовываем несколько картинок\n",
        "plot_gallery(dataset, from_torch=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rRUmrsI3jmM"
      },
      "source": [
        "Делим датасет на train/val и создаем даталоадеры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92DMc6BfMG5O"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(dataset) * 0.8)\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "g_cpu = torch.Generator().manual_seed(8888)\n",
        "train_data, val_data = torch.utils.data.random_split(dataset, [train_size, val_size], generator=g_cpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPRz737NVdyW"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asnhHgjSACuz"
      },
      "source": [
        "## Задание: Создание модели Vanilla AE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoLIyu9-6I78"
      },
      "source": [
        "Ваша задача — реализовать класс атоэнкодера для данных. За основу можно взять класс сети для сегментации U-Net с прошлого домашнего задания. Так как автоэнкодер — это тоже encoder-decoder архитектура, нам понадобится внести лишь немного изменений:\n",
        "- В U-Net был skip connection, в автоэнкодере его быть не должно;\n",
        "- Обратите внимание на то, сколько карт активации должно быть в последнем слое сети.\n",
        "- в середине сети не должно быть среднего слоя, как было в U-Net\n",
        "\n",
        "Вы можете варьировать количества блоков/слоев и устройства блоков. Архитектура блока, как в предыдущем домашнем задании (conv -> bn -> relu -> maxpool) подойдет."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJrda_0eMU9R"
      },
      "outputs": [],
      "source": [
        "def encoder_block(in_channels, out_channels, kernel_size, padding):\n",
        "    '''\n",
        "    блок, который принимает на вход карты активации с количеством каналов in_channels, \n",
        "    и выдает на выход карты активации с количеством каналов out_channels\n",
        "    kernel_size, padding — параметры conv слоев внутри блока\n",
        "    '''\n",
        "    block = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    return block\n",
        "\n",
        "def decoder_block(in_channels, out_channels, kernel_size, padding):\n",
        "    '''\n",
        "    блок, который принимает на вход карты активации с количеством каналов in_channels, \n",
        "    и выдает на выход карты активации с количеством каналов out_channels\n",
        "    kernel_size, padding — параметры conv слоев внутри блока\n",
        "    '''\n",
        "    block = nn.Sequential(\n",
        "        # ВАШ КОД ТУТ\n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "    )\n",
        "\n",
        "    return block\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        # добавьте несколько слоев encoder block\n",
        "        # это блоки-составляющие энкодер-части сети\n",
        "        self.encoder = nn.Sequential(\n",
        "            # ВАШ КОД ТУТ\n",
        "            # in: 3 x 64 x 64\n",
        "            encoder_block(3, 64, 3, 1), # out: 64 x 32 x 32\n",
        "            encoder_block(64, 128, 3, 1), # out: 128 x 16 x 16\n",
        "            encoder_block(128, 256, 3, 1) # out: 256 x 8 x 8\n",
        "        )\n",
        "\n",
        "        # добавьте несколько слоев decoder block\n",
        "        # это блоки-составляющие декодер-части сети\n",
        "        self.decoder = nn.Sequential(\n",
        "            # ВАШ КОД ТУТ\n",
        "            # in: 256 x 8 x 8\n",
        "            decoder_block(256, 128, 3, 1), # out: 128 x 16 x 16\n",
        "            decoder_block(128, 64, 3, 1), # out: 64 x 32 x 32\n",
        "            decoder_block(64, 3, 3, 1) # out: 3 x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # downsampling \n",
        "        latent = self.encoder(x)\n",
        "\n",
        "        # upsampling\n",
        "        reconstruction = self.decoder(latent)\n",
        "\n",
        "        return reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6-LSkda5IGr"
      },
      "source": [
        "Ячейка ниже проверяет, что модель работает правильно:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezQXjpkb5FB3"
      },
      "outputs": [],
      "source": [
        "# проверка, что у модели есть обучаемые слои\n",
        "model = Autoencoder()\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "assert num_params > 10\n",
        "\n",
        "# проверка, что модель собрана верно\n",
        "random_tensor = torch.Tensor(np.random.random((32, 3, 64, 64)))\n",
        "model = Autoencoder()\n",
        "out = model(random_tensor)\n",
        "assert out.shape == (32, 3, 64, 64), \"неверный размер выхода модели\"\n",
        "\n",
        "# проверка, что у модели можно отцепить декодер и использовать его как\n",
        "# отдельную модель\n",
        "# если здесь возникла ошибка, убедитесь, что в вашей сети нет skip connection\n",
        "random_tensor = torch.Tensor(np.random.random((32, 3, 64, 64)))\n",
        "model = Autoencoder()\n",
        "latent_shape = model.encoder(random_tensor).shape\n",
        "latent = torch.Tensor(np.random.random(latent_shape))\n",
        "out = model.decoder(latent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc5906xi7bIh"
      },
      "source": [
        "### Сдача задания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQZGIemr7eD0"
      },
      "source": [
        "Если обе ячейки отработали без ошибок, можно сдавать задание в первую задачу на Я.Контесте. Для этого нужно скопировать класс Autoencoder в нужное место в submission_template10.py и отправить submission_template10.py в Я.Контест."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t7fO9oo8wgJ"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJmiONJ78zgf"
      },
      "source": [
        "Теперь вы можете обучить на данных созданную вами модель. Код для этого написан ниже. В процессе обучения вы будете видеть, насколько хорошо модель учится восстанавливать лица людей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTSK7GsOMlek"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
        "def denorm(img_tensors):\n",
        "    return img_tensors * stats[1][0] + stats[0][0]\n",
        "\n",
        "def train(model, opt, loss_fn, epochs, train_loader, val_loader):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # печатаем номер текущей эпохи\n",
        "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
        "\n",
        "        # 1. Обучаем сеть на картинках из train_loader\n",
        "        model.train()  # train mode\n",
        "\n",
        "        avg_train_loss = 0\n",
        "        for i, X_batch in enumerate(train_loader):\n",
        "            # переносим батч на GPU\n",
        "            X_batch = X_batch.to(device)\n",
        "            # получаем ответы сети на батч\n",
        "            Y_pred = model(X_batch)\n",
        "\n",
        "            # считаем лосс, делаем шаг оптимизации сети\n",
        "            loss = loss_fn(Y_pred, X_batch)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            avg_train_loss += loss / len(train_loader)\n",
        "\n",
        "        # выводим средний лосс на тренировочной выборке за эпоху\n",
        "        print('avg train loss: %f' % avg_train_loss)\n",
        "\n",
        "        # 2. Тестируем сеть на картинках из val_loader\n",
        "        model.eval()\n",
        "\n",
        "        avg_val_loss = 0\n",
        "        for i, X_batch in enumerate(val_loader):\n",
        "            # переносим батч на GPU\n",
        "            X_batch = X_batch.to(device)\n",
        "            # получаем ответы сети на батч\n",
        "            Y_pred = model(X_batch)\n",
        "            # считаем лосс на батче\n",
        "            loss = loss_fn(Y_pred, X_batch)\n",
        "\n",
        "            avg_val_loss += loss / len(val_loader)\n",
        "\n",
        "        # выводим средний лосс на валидационных данных\n",
        "        print('avg val loss: %f' % avg_val_loss)\n",
        "\n",
        "\n",
        "        # 3. Визуализируем ответы сети на шести картинках из валидационных данных\n",
        "\n",
        "        # получаем один батч из data_val\n",
        "        X_val = next(iter(val_loader))\n",
        "        # получаем ответ сети на картинки из батча\n",
        "        Y_pred = model(X_val.to(device))\n",
        "        Y_hat = Y_pred.detach().cpu().numpy()\n",
        "        Y_hat = np.argmax(Y_hat, axis=1)\n",
        "\n",
        "        # удаляем предыдущую визуализацию\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        _, axes = plt.subplots(2, 6, figsize=(6*4, 2*4))\n",
        "        for k in range(6):\n",
        "            # отрисовываем 6 картинок, поданных на вход сети\n",
        "            # картинки нормализованы, поэтому могут выглядеть непривычно\n",
        "            axes[0][k].imshow(denorm(X_val[k].data.cpu().numpy()).transpose(1, 2, 0), aspect='auto')\n",
        "            axes[0][k].title.set_text('Input')\n",
        "\n",
        "            # отрисовываем ответы сети для каждого из четырех классов сегментации в отдельности\n",
        "            axes[1][k].imshow(denorm(Y_pred[k].data.cpu().numpy()).transpose(1, 2, 0), aspect='auto')\n",
        "            axes[1][k].title.set_text('Output')\n",
        "        plt.suptitle('%d / %d - val loss: %f' % (epoch+1, epochs, avg_val_loss))\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcF8iAoCOI_7"
      },
      "outputs": [],
      "source": [
        "autoencoder = Autoencoder().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
        "\n",
        "train(autoencoder, optimizer, criterion, 10, train_loader, val_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
